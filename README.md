# unifying-sketch-text-photo
Msc Dissertation

## Aim
To learn a common unified embedding space that can encode any modality. In this case, focus is placed on three main modalities - sketches, text and photo. This will be evaluated on scene retrieval tasks like:
1. Fine-Grained Sketch Based Image Retrieval (FG-SBIR)
2. Fine-Grained Text Based Image Retrieval (FG-TBIR)
3. Fine-Grained Sketch + Text Based Image Retrieval (FG-STBIR)

## Dataset
Filtered version of SketchyCOCO to obtain only object level scene-sketches

Datasets used: 

1. [SketchyCOCO: Image Generation from Freehand Scene Sketches](https://github.com/sysu-imsl/SketchyCOCO)
2. [MSCOCO](https://cocodataset.org/#home)

## Proposed plan and preliminary results

For further details, please check the following presentation - [Unifying Sketch, Text and Photo](https://github.com/ramyapriya/unifying-sketch-text-photo/blob/main/Unifying%20Sketch%2C%20Text%20and%20Photo.pdf)
